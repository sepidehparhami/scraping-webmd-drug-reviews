{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Scraping WebMD Drug Reviews\n## Introduction\nWhile documents from medical encounters are safeguarded by laws such as HIPAA in the US, there are a number of public websites where patients are nonetheless sharing health information that may prove valuable as a data source. One such site is WebMD, which provides a database of prescription drugs and solicits reviews from patients about their experience with the medications.\n\nPython's `requests` and `BeautifulSoup` libraries make it relatively simple to scrape data from any webpage, and this notebook can be used with only a few modifications to collect user reviews for any medication in WebMD's database for use in downstream analysis. Each review consists of demographic information about the patient, a set of ratings on a scale of 1 to 5 stars, and unstructured text.\n\nThis notebook focuses on compiling reviews for various medications used to treat depression. Because psychoactive medication works to alter people's thoughts, feelings, and behavior, firsthand narratives written by patients taking these medications are especially valuable as a source of insight into how well a treatment worked and possible explanations as to why.","metadata":{}},{"cell_type":"markdown","source":"## Setup","metadata":{}},{"cell_type":"code","source":"# imports\nimport requests\nimport numpy as np\nimport pandas as pd\nimport regex as re","metadata":{"execution":{"iopub.status.busy":"2024-03-05T19:38:37.231139Z","iopub.execute_input":"2024-03-05T19:38:37.232087Z","iopub.status.idle":"2024-03-05T19:38:37.766031Z","shell.execute_reply.started":"2024-03-05T19:38:37.232047Z","shell.execute_reply":"2024-03-05T19:38:37.765061Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Functions","metadata":{}},{"cell_type":"code","source":"# regular expressions for parsing data from a single review\n# elements found in review-details div\ndef regex_date(review):\n    '''Parses the date of the review in format dd/mm/yyyy'''\n    return re.findall(r'\\d+/\\d+/\\d+', review.find('div', class_='date').text)[0]\n\ndef regex_condition(review):\n    '''Parses the condition for which the medication is used'''\n    condition_element = review.find('strong', class_='condition')\n    condition_listed = condition_element is not None\n    if condition_listed:\n        # TODO: be able to match ''\"Change of Life\" Signs' condition\n        condition_match = re.findall(r'(?<=Condition:\\s)\\w+(?:\\s\\w+)*', condition_element.text)\n    return condition_match[0] if (condition_listed and len(condition_match) > 0) else np.nan\n\ndef regex_rating_overall(review):\n    '''Parses the overall rating, the average of 3 categories'''\n    rating_overall_line = review.find('div', class_='overall-rating').strong.text\n    return re.findall(r'\\d+.\\d+', rating_overall_line)\n\ndef regex_rating_category(review, ind_cat):\n    '''Parses the rating for the category at index ind_cat in ['effectiveness', 'ease_of_use', 'satisfaction']'''\n    rating_categories = review.find('div', class_='categories').find_all('section')\n    div = rating_categories[ind_cat].find('div', class_='webmd-rate on-mobile')\n    return int(div.get('aria-valuenow'))\n\ndef regex_text(review):\n    '''Parses the free response text review for the drug'''\n    text_line = review.find('p', class_='description-text')\n    return text_line.text if text_line is not None else np.nan","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# regular expressions for parsing data from a single review\n# elements found in details div\ndef regex_age(details):\n    '''Parses the age of the medication user'''\n    age_match = re.findall(r'(?<=\\|\\s+)\\d+-\\d+', details)\n    return age_match[0] if len(age_match) > 0 else np.nan\n\ndef regex_gender(details):\n    '''Parses the gender of the medication user'''\n    gender_match = re.findall(r'(?<=\\|\\s+)Male|Female', details)\n    return gender_match[0] if len(gender_match) > 0 else np.nan\n\ndef regex_time(details):\n    '''Parses the duration of time on drug'''\n    time_match = re.findall(r'(?<=On\\smedication\\sfor\\s)\\w+(?:\\s\\w+)*', details)\n    return time_match[0] if len(time_match) > 0 else np.nan\n\ndef regex_reviewer(details):\n    '''Parses the type of reviewer'''\n    reviewer_match = re.findall(r'(?<=\\|\\s+)\\w+(?:\\s\\w+)*(?=\\s*$)', details)\n    return reviewer_match[0] if len(reviewer_match) > 0 else np.nan","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# parse the reviews on a single webpage\ndef parse_reviews_page(reviews_html, drug_name, reviews_df):\n    '''Populates reviews_df data frame with records from 1 page's reviews\n    \n    Parameters:\n    reviews_html (str): HTML for the webpage extracted using BeautifulSoup\n    drug_name (str): the name of the drug being reviewed\n    reviews_df (pd.DataFrame): dataframe with one row per review\n    \n    Returns:\n    pd.DataFrame: reviews_df dataframe with new records appended\n    \n    '''\n    \n    # loop over reviews from a single page\n    for i, review in enumerate(reviews_html):\n        to_append = pd.DataFrame([pd.Series([None]*len(cols), index=cols)])\n        \n        details = review.find('div', class_='details').text\n\n        to_append['drug_name'] = drug_name\n        to_append['date'] = regex_date(review)\n        to_append['age'] = regex_age(details)\n        to_append['gender'] = regex_gender(details)\n        to_append['time_on_drug'] = regex_time(details)\n        to_append['reviewer_type'] = regex_reviewer(details)\n        to_append['condition'] = regex_condition(review)\n        to_append['rating_overall'] = regex_rating_overall(review)\n        \n        for ind_cat, cat in enumerate(['effectiveness', 'ease_of_use', 'satisfaction']):\n            to_append[f'rating_{cat}'] = regex_rating_category(review)\n    \n        to_append['text'] = regex_text(review)\n        reviews_df = pd.concat([reviews_df, to_append], ignore_index=True)\n        \n    return reviews_df","metadata":{"execution":{"iopub.status.busy":"2023-12-12T21:19:01.778785Z","iopub.execute_input":"2023-12-12T21:19:01.779249Z","iopub.status.idle":"2023-12-12T21:19:01.797132Z","shell.execute_reply.started":"2023-12-12T21:19:01.779213Z","shell.execute_reply":"2023-12-12T21:19:01.795760Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# crawl over the review pages for one drug\ndef crawl_reviews_pages(reviews_df):\n    '''Crawls a drug's reviews page-by-page, saving each page's reviews into reviews_df\n    \n    Parameters:\n    reviews_df (pd.DataFrame): dataframe with one row per review\n    \n    Returns:\n    pd.DataFrame: reviews_df dataframe with new records appended\n    \n    '''\n    \n    counter = 0\n    curr_page = 0\n    pages_left = True\n    while pages_left:\n        curr_page += 1\n\n        if (curr_page % 15) == 0:\n            print(f'Scraping page {curr_page} of {last_page}')\n\n        curr_url = review_url + f'&page={curr_page}'\n        response = requests.get(curr_url, headers=headers).content\n        soup = BeautifulSoup(response, 'lxml')\n        reviews_page_html = soup.find_all('div', class_='review-details') # get elements that hold each review\n        pages = soup.find('ul', class_='pagination')\n        last_page = int(pages.find_all('li', class_='page-item')[-1].text.strip())\n\n        page_title = soup.title.text\n        drug_name = re.findall(r'(.*)(?=\\sReviews)', page_title)[0]\n\n        reviews_df = parse_reviews_page(reviews_page_html, drug_name, reviews_df)\n\n        if curr_page >= last_page:\n            pages_left = False\n            \n    return reviews_df","metadata":{"execution":{"iopub.status.busy":"2023-12-12T21:19:02.450578Z","iopub.execute_input":"2023-12-12T21:19:02.451063Z","iopub.status.idle":"2023-12-12T21:19:02.461606Z","shell.execute_reply.started":"2023-12-12T21:19:02.451023Z","shell.execute_reply":"2023-12-12T21:19:02.460332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scrape Names of Depression Drugs from WebMD List","metadata":{}},{"cell_type":"code","source":"# need to spoof a browser in order to not get blocked when making request\n# https://bar.rady.ucsd.edu/Web_Scraping.html\nfrom bs4 import BeautifulSoup\n\nheaders = requests.utils.default_headers()\nheaders.update({\n    'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0',\n})","metadata":{"execution":{"iopub.status.busy":"2023-12-12T21:19:03.062676Z","iopub.execute_input":"2023-12-12T21:19:03.063115Z","iopub.status.idle":"2023-12-12T21:19:03.408269Z","shell.execute_reply.started":"2023-12-12T21:19:03.063079Z","shell.execute_reply":"2023-12-12T21:19:03.406347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# list of depression drugs from WebMD\nurl = 'https://www.webmd.com/depression/depression-medications-antidepressants'\nresponse = requests.get(url, headers=headers).content\nsoup = BeautifulSoup(response, 'lxml')\ndrugs_section = soup.find('div', class_='article-page active-page')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make empty data frame to contain values and full text from each review\ncols = ['drug_name',\n       'date',\n       'age',\n       'gender',\n       'time_on_drug',\n       'reviewer_type',\n       'condition',\n       'rating_overall',\n       'rating_effectiveness',\n       'rating_ease_of_use',\n       'rating_satisfaction',\n       'text']\n\nreviews_df = pd.DataFrame(columns=cols, index=[])\n\n# TODO: change parsing so that it looks for reviews.webmd.com in case ordering of tabs changes\nfor drug in drugs_section.find_all('p'):\n    link = drug.a.get('href')\n    response = requests.get(link, headers=headers, allow_redirects=True)\n    \n    # if the link on the depression medications page redirects to a generic page (no dedicated page for the drug exists), skip it\n    new_link = response.url\n    redirected_links = ['https://www.webmd.com/depression/optimizing-depression-medicines',\n                       'https://www.webmd.com/drugs/2/index']\n    if new_link in redirected_links:\n        print(f'skipping 1 drug with link {new_link}')\n        continue\n        \n    # the link for Vraylar leads to search results, but with only 1 result - load that result page\n    if new_link == 'https://www.webmd.com/drugs/2/search?type=drugs&query=vraylar':\n        vraylar_link = 'https://www.webmd.com/drugs/2/drug-170027/vraylar-oral/details'\n        response = requests.get(vraylar_link, headers=headers, allow_redirects=True)\n    \n    drug_page = BeautifulSoup(response.content, 'lxml')\n    \n    drug_review_element = drug_page.find('ul', class_='auto-tabs').find_all('li')[-1] # get the data for the last tab, Reviews\n    review_url = drug_review_element.a.get('href')\n        \n    print(review_url)\n    # reviews_df = crawl_reviews_pages(reviews_df)\n    \nreviews_df.to_csv('psychiatric_drug_webmd_reviews.csv')","metadata":{"execution":{"iopub.status.busy":"2023-12-12T21:36:01.364282Z","iopub.execute_input":"2023-12-12T21:36:01.364738Z","iopub.status.idle":"2023-12-12T21:36:28.525867Z","shell.execute_reply.started":"2023-12-12T21:36:01.364701Z","shell.execute_reply":"2023-12-12T21:36:28.524535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n","metadata":{}}]}